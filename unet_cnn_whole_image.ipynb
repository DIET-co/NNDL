{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "im-w0Wo3C8Xa",
        "outputId": "73b2f903-3340-495f-cd0d-f7447168c88e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Path to the folders containing images and masks\n",
        "image_folder = \"/content/gdrive/MyDrive/ORGINAL_img\"\n",
        "mask_folder = \"/content/gdrive/MyDrive/ORIGINAL_mask\"\n",
        "\n",
        "# Get the list of image and mask filenames\n",
        "image_filenames = sorted(os.listdir(image_folder))\n",
        "mask_filenames = sorted(os.listdir(mask_folder))\n",
        "\n",
        "# Data normalization function\n",
        "def normalize_data(data):\n",
        "    return data / 255.0\n",
        "\n",
        "# Initialize empty lists to store normalized images and masks\n",
        "normalized_images = []\n",
        "normalized_masks = []\n",
        "\n",
        "# Iterate over the image and mask filenames\n",
        "for i in range(len(image_filenames)):\n",
        "    # Load image and mask\n",
        "    image_filename = os.path.join(image_folder, image_filenames[i])\n",
        "    mask_filename = os.path.join(mask_folder, mask_filenames[i])\n",
        "    image = cv2.imread(image_filename)\n",
        "    mask = cv2.imread(mask_filename, cv2.IMREAD_GRAYSCALE)\n",
        "    new_size = (384, 96)\n",
        "    image_resized = cv2.resize(image, new_size)\n",
        "    mask_resized = cv2.resize(mask, new_size)\n",
        "    # Normalize image and mask\n",
        "    normalized_image = normalize_data(image_resized)\n",
        "    normalized_mask = normalize_data(mask_resized)\n",
        "    # Binarize the mask (optional)\n",
        "    normalized_mask = np.where(normalized_mask > 0.5, 1, 0)\n",
        "\n",
        "    # Append normalized images and masks to the respective lists\n",
        "    normalized_images.append(normalized_image)\n",
        "    normalized_masks.append(normalized_mask)\n",
        "\n",
        "# Convert the image and mask lists to numpy arrays\n",
        "normalized_images = np.array(normalized_images)\n",
        "normalized_masks = np.array(normalized_masks)\n",
        "\n",
        "# Split the data into training and validation sets (adjust the split ratio as desired)\n",
        "split_ratio = 0.8\n",
        "split_index = int(len(normalized_images) * split_ratio)\n",
        "train_images = normalized_images[:split_index]\n",
        "train_masks = normalized_masks[:split_index]\n",
        "val_images = normalized_images[split_index:]\n",
        "val_masks = normalized_masks[split_index:]\n",
        "\n",
        "# Convert validation masks to labels\n",
        "val_labels = val_masks[..., np.newaxis]\n",
        "\n",
        "# U-Net model for binarization\n",
        "def unet():\n",
        "    inputs = keras.layers.Input(shape=(96, 384, 3))\n",
        "\n",
        "    # Encoder\n",
        "    conv1 = keras.layers.Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
        "    conv1 = keras.layers.Conv2D(64, 3, activation='relu', padding='same')(conv1)\n",
        "    pool1 = keras.layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "    conv2 = keras.layers.Conv2D(128, 3, activation='relu', padding='same')(pool1)\n",
        "    conv2 = keras.layers.Conv2D(128, 3, activation='relu', padding='same')(conv2)\n",
        "    pool2 = keras.layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "    conv3 = keras.layers.Conv2D(256, 3, activation='relu', padding='same')(pool2)\n",
        "    conv3 = keras.layers.Conv2D(256, 3, activation='relu', padding='same')(conv3)\n",
        "    pool3 = keras.layers.MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "    conv4 = keras.layers.Conv2D(512, 3, activation='relu', padding='same')(pool3)\n",
        "    conv4 = keras.layers.Conv2D(512, 3, activation='relu', padding='same')(conv4)\n",
        "    pool4 = keras.layers.MaxPooling2D(pool_size=(2, 2))(conv4)\n",
        "\n",
        "    conv5 = keras.layers.Conv2D(1024, 3, activation='relu', padding='same')(pool4)\n",
        "    conv5 = keras.layers.Conv2D(1024, 3, activation='relu', padding='same')(conv5)\n",
        "\n",
        "    # Decoder\n",
        "    up6 = keras.layers.Conv2DTranspose(512, 2, strides=(2, 2), padding='same')(conv5)\n",
        "    concat6 = keras.layers.concatenate([up6, conv4], axis=3)\n",
        "    conv6 = keras.layers.Conv2D(512, 3, activation='relu', padding='same')(concat6)\n",
        "    conv6 = keras.layers.Conv2D(512, 3, activation='relu', padding='same')(conv6)\n",
        "\n",
        "    up7 = keras.layers.Conv2DTranspose(256, 2, strides=(2, 2), padding='same')(conv6)\n",
        "    concat7 = keras.layers.concatenate([up7, conv3], axis=3)\n",
        "    conv7 = keras.layers.Conv2D(256, 3, activation='relu', padding='same')(concat7)\n",
        "    conv7 = keras.layers.Conv2D(256, 3, activation='relu', padding='same')(conv7)\n",
        "\n",
        "    up8 = keras.layers.Conv2DTranspose(128, 2, strides=(2, 2), padding='same')(conv7)\n",
        "    concat8 = keras.layers.concatenate([up8, conv2], axis=3)\n",
        "    conv8 = keras.layers.Conv2D(128, 3, activation='relu', padding='same')(concat8)\n",
        "    conv8 = keras.layers.Conv2D(128, 3, activation='relu', padding='same')(conv8)\n",
        "\n",
        "    up9 = keras.layers.Conv2DTranspose(64, 2, strides=(2, 2), padding='same') (conv8)\n",
        "    concat9 = keras.layers.concatenate([up9, conv1], axis=3)\n",
        "    conv9 = keras.layers.Conv2D(64, 3, activation='relu', padding='same')(concat9)\n",
        "    conv9 = keras.layers.Conv2D(64, 3, activation='relu', padding='same')(conv9)\n",
        "\n",
        "    output = keras.layers.Conv2D(1, 1, activation='sigmoid')(conv9)\n",
        "\n",
        "    model = keras.models.Model(inputs=inputs, outputs=output)\n",
        "    return model\n",
        "\n",
        "# Create the U-Net model\n",
        "model = unet()\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model and collect the history\n",
        "history = model.fit(train_images, train_masks, validation_data=(val_images, val_masks), epochs=20, batch_size=8)\n",
        "\n",
        "# Get the training metrics\n",
        "train_loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "train_acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "# Plot the training loss and validation loss\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Plot the training accuracy and validation accuracy\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(train_acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "# Display the plots\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "FAJsNSUVDKBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"U-NET_whole_image.h5\")"
      ],
      "metadata": {
        "id": "JlDYGlO-Dvn4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "model = keras.models.load_model(\"/content/gdrive/MyDrive/U-NET_whole_image.h5\")"
      ],
      "metadata": {
        "id": "02FDCjYeD712"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import precision_recall_curve, average_precision_score, roc_curve, auc\n",
        "from skimage.metrics import structural_similarity\n",
        "\n",
        "# Path to the folders containing images and masks\n",
        "image_folder = \"/content/gdrive/MyDrive/TEST_original\"\n",
        "mask_folder = \"/content/gdrive/MyDrive/TEST_mask\"\n",
        "\n",
        "# Get the list of image and mask filenames\n",
        "image_filenames = sorted(os.listdir(image_folder))\n",
        "mask_filenames = sorted(os.listdir(mask_folder))\n",
        "\n",
        "# Data normalization function\n",
        "def normalize_data(data):\n",
        "    return data / 255.0\n",
        "\n",
        "# Initialize empty lists to store normalized images and masks\n",
        "normalized_images = []\n",
        "normalized_masks = []\n",
        "\n",
        "# Iterate over the image and mask filenames\n",
        "for i in range(len(image_filenames)):\n",
        "    # Load image and mask\n",
        "    image_filename = os.path.join(image_folder, image_filenames[i])\n",
        "    mask_filename = os.path.join(mask_folder, mask_filenames[i])\n",
        "    image = cv2.imread(image_filename)\n",
        "    mask = cv2.imread(mask_filename, cv2.IMREAD_GRAYSCALE)\n",
        "    new_size = (384, 96)\n",
        "    image_resized = cv2.resize(image, new_size)\n",
        "    mask_resized = cv2.resize(mask, new_size)\n",
        "    # Normalize image and mask\n",
        "    normalized_image = normalize_data(image_resized)\n",
        "    normalized_mask = normalize_data(mask_resized)\n",
        "    # Binarize the mask (optional)\n",
        "    normalized_mask = np.where(normalized_mask > 0.5, 1, 0)\n",
        "\n",
        "    # Append normalized images and masks to the respective lists\n",
        "    normalized_images.append(normalized_image)\n",
        "    normalized_masks.append(normalized_mask)\n",
        "\n",
        "# Convert the image and mask lists to numpy arrays\n",
        "normalized_images = np.array(normalized_images)\n",
        "normalized_masks = np.array(normalized_masks)\n",
        "\n",
        "# Choose the index of the image you want to test\n",
        "image_index = 30\n",
        "\n",
        "# Get the corresponding test image and mask\n",
        "test_image = normalized_images[image_index]\n",
        "test_mask = normalized_masks[image_index]\n",
        "\n",
        "# Convert the test image and mask to numpy arrays\n",
        "test_images = np.expand_dims(test_image, axis=0)\n",
        "test_masks = np.expand_dims(test_mask, axis=0)\n",
        "\n",
        "# Make predictions on the test image\n",
        "predictions = model.predict(test_images)\n",
        "\n",
        "# Display the test image, ground truth mask, and predicted mask\n",
        "fig = plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.imshow(test_image)\n",
        "plt.title(\"Test Image\", fontsize=14)\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.imshow(test_mask, cmap='gray')\n",
        "plt.title(\"Ground Truth Mask\", fontsize=14)\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "predicted_mask = np.squeeze(predictions)  # Remove the batch dimension\n",
        "predicted_mask = np.where(predicted_mask > 0.6, 1, 0)  # Binarize the predicted mask\n",
        "plt.imshow(predicted_mask, cmap='gray')\n",
        "plt.title(\"Predicted Mask\", fontsize=14)\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Save the ground truth mask\n",
        "plt.imsave(\"ground_truth_mask.png\", test_mask, cmap='gray')\n",
        "\n",
        "# Save the predicted mask\n",
        "plt.imsave(\"predicted_mask.png\", predicted_mask, cmap='gray')\n",
        "\n",
        "# Flatten the ground truth mask and predicted mask\n",
        "ground_truth_mask_flat = test_mask.flatten()\n",
        "predicted_mask_flat = predicted_mask.flatten()\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision, recall, _ = precision_recall_curve(ground_truth_mask_flat, predicted_mask_flat)\n",
        "f1 = 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "# Calculate ROC curve and AUC\n",
        "fpr, tpr, _ = roc_curve(ground_truth_mask_flat, predicted_mask_flat)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# Calculate PSNR\n",
        "def calculate_psnr(y_true, y_pred):\n",
        "    mse = np.mean((y_true - y_pred) ** 2)\n",
        "    max_pixel = 1.0  # Assuming pixel values are in the range [0, 1]\n",
        "    psnr = 20 * np.log10(max_pixel / np.sqrt(mse))\n",
        "    return psnr\n",
        "\n",
        "# Calculate DRD\n",
        "def calculate_drd(y_true, y_pred):\n",
        "    drd = np.mean(np.abs(y_true - y_pred))\n",
        "    return drd\n",
        "\n",
        "\n",
        "# Calculate IoU and mAP\n",
        "def calculate_iou(y_true, y_pred):\n",
        "    intersection = np.logical_and(y_true, y_pred)\n",
        "    union = np.logical_or(y_true, y_pred)\n",
        "    iou = np.sum(intersection) / np.sum(union)\n",
        "    return iou\n",
        "\n",
        "\n",
        "\n",
        "def calculate_ap(y_true, y_pred):\n",
        "    # Flatten the masks\n",
        "    y_true_flat = y_true.flatten()\n",
        "    y_pred_flat = y_pred.flatten()\n",
        "\n",
        "\n",
        "\n",
        "psnr = calculate_psnr(test_mask, predicted_mask)\n",
        "drd = calculate_drd(test_mask, predicted_mask)\n",
        "\n",
        "# Calculate Intersection-over-Union (IoU) and mean Average Precision (mAP)\n",
        "iou = calculate_iou(test_mask, predicted_mask)\n",
        "ap = calculate_ap(test_mask, predicted_mask)\n",
        "\n",
        "# Calculate Structural Similarity (SSIM)\n",
        "ssim = structural_similarity(test_mask, predicted_mask)\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n",
        "print(\"AUC:\", roc_auc)\n",
        "print(\"Peak Signal-to-Noise Ratio (PSNR):\", psnr)\n",
        "print(\"Dynamic Range Difference (DRD):\", drd)\n",
        "print(\"Intersection-over-Union (IoU):\", iou)\n",
        "print(\"Mean Average Precision (mAP):\", ap)\n",
        "print(\"Structural Similarity (SSIM):\", ssim)\n",
        "\n",
        "# Plot ROC curve\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, label='ROC curve (AUC = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "3mQne8poEC4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install visualkeras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwymazzWE56P",
        "outputId": "fe0d8c0f-8656-41f1-d17e-3d70f4abdef8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting visualkeras\n",
            "  Downloading visualkeras-0.0.2-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from visualkeras) (8.4.0)\n",
            "Requirement already satisfied: numpy>=1.18.1 in /usr/local/lib/python3.10/dist-packages (from visualkeras) (1.22.4)\n",
            "Collecting aggdraw>=1.3.11 (from visualkeras)\n",
            "  Downloading aggdraw-1.3.16-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (993 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m993.0/993.0 kB\u001b[0m \u001b[31m56.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: aggdraw, visualkeras\n",
            "Successfully installed aggdraw-1.3.16 visualkeras-0.0.2\n"
          ]
        }
      ]
    }
  ]
}