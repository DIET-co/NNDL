{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYxxqRRMFaxm",
        "outputId": "f1c68e01-38e7-4a98-ed50-49bfa3653d48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtNHVT9qFoL5",
        "outputId": "d9f72a85-106b-4d87-d21c-4ad02f5e7912"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "458/458 [==============================] - 107s 157ms/step - loss: 0.6230 - accuracy: 2.9631e-08\n",
            "Epoch 2/20\n",
            "458/458 [==============================] - 66s 144ms/step - loss: 0.6205 - accuracy: 2.9631e-08\n",
            "Epoch 3/20\n",
            "458/458 [==============================] - 66s 145ms/step - loss: 0.6204 - accuracy: 2.9631e-08\n",
            "Epoch 4/20\n",
            "458/458 [==============================] - 66s 144ms/step - loss: 0.6199 - accuracy: 2.9631e-08\n",
            "Epoch 5/20\n",
            "458/458 [==============================] - 66s 144ms/step - loss: 0.6201 - accuracy: 2.9631e-08\n",
            "Epoch 6/20\n",
            "458/458 [==============================] - 66s 144ms/step - loss: 0.6198 - accuracy: 2.9631e-08\n",
            "Epoch 7/20\n",
            "458/458 [==============================] - 66s 144ms/step - loss: 0.6200 - accuracy: 2.9631e-08\n",
            "Epoch 8/20\n",
            "458/458 [==============================] - 66s 144ms/step - loss: 0.6200 - accuracy: 2.9631e-08\n",
            "Epoch 9/20\n",
            "458/458 [==============================] - 66s 143ms/step - loss: 0.6198 - accuracy: 2.9631e-08\n",
            "Epoch 10/20\n",
            "458/458 [==============================] - 66s 143ms/step - loss: 0.6199 - accuracy: 2.9631e-08\n",
            "Epoch 11/20\n",
            "458/458 [==============================] - 66s 143ms/step - loss: 0.6198 - accuracy: 2.9631e-08\n",
            "Epoch 12/20\n",
            "458/458 [==============================] - 66s 143ms/step - loss: 0.6200 - accuracy: 2.9631e-08\n",
            "Epoch 13/20\n",
            "458/458 [==============================] - 66s 143ms/step - loss: 0.6197 - accuracy: 2.9631e-08\n",
            "Epoch 14/20\n",
            "458/458 [==============================] - 65s 143ms/step - loss: 0.6198 - accuracy: 2.9631e-08\n",
            "Epoch 15/20\n",
            "458/458 [==============================] - 66s 143ms/step - loss: 0.6198 - accuracy: 2.9631e-08\n",
            "Epoch 16/20\n",
            "458/458 [==============================] - 65s 142ms/step - loss: 0.6198 - accuracy: 2.9631e-08\n",
            "Epoch 17/20\n",
            "458/458 [==============================] - 65s 142ms/step - loss: 0.6198 - accuracy: 2.9631e-08\n",
            "Epoch 18/20\n",
            "458/458 [==============================] - 65s 142ms/step - loss: 0.6198 - accuracy: 2.9631e-08\n",
            "Epoch 19/20\n",
            "458/458 [==============================] - 65s 143ms/step - loss: 0.6198 - accuracy: 2.9631e-08\n",
            "Epoch 20/20\n",
            "458/458 [==============================] - 65s 142ms/step - loss: 0.6197 - accuracy: 2.9631e-08\n",
            "15/15 [==============================] - 14s 446ms/step - loss: 0.6476 - accuracy: 0.0000e+00\n",
            "Validation Loss: 0.6475825309753418\n",
            "Validation Accuracy: 0.0\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from tensorflow import keras\n",
        "\n",
        "# Path to the folders containing images and masks\n",
        "image_folder = \"/content/gdrive/MyDrive/ORGINAL_img\"\n",
        "mask_folder = \"/content/gdrive/MyDrive/ORGINAL_img\"\n",
        "\n",
        "# Get the list of image and mask filenames\n",
        "image_filenames = sorted(os.listdir(image_folder))\n",
        "mask_filenames = sorted(os.listdir(mask_folder))\n",
        "\n",
        "# Data normalization function\n",
        "def normalize_data(data):\n",
        "    return data / 255.0\n",
        "\n",
        "# Initialize empty lists to store normalized images and masks\n",
        "normalized_images = []\n",
        "normalized_masks = []\n",
        "\n",
        "# Chunk size for dividing the images and masks\n",
        "chunk_size = 256\n",
        "\n",
        "# Iterate over the image and mask filenames\n",
        "for i in range(len(image_filenames)):\n",
        "    # Load image and mask\n",
        "    image_filename = os.path.join(image_folder, image_filenames[i])\n",
        "    mask_filename = os.path.join(mask_folder, mask_filenames[i])\n",
        "    image = cv2.imread(image_filename)\n",
        "    mask = cv2.imread(mask_filename, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    # Divide the image and mask into chunks\n",
        "    image_chunks = [image[y:y+chunk_size, x:x+chunk_size] for y in range(0, image.shape[0], chunk_size) for x in range(0, image.shape[1], chunk_size)]\n",
        "    mask_chunks = [mask[y:y+chunk_size, x:x+chunk_size] for y in range(0, mask.shape[0], chunk_size) for x in range(0, mask.shape[1], chunk_size)]\n",
        "\n",
        "    # Normalize image and mask chunks\n",
        "    normalized_image_chunks = [normalize_data(chunk) for chunk in image_chunks]\n",
        "    normalized_mask_chunks = [normalize_data(chunk) for chunk in mask_chunks]\n",
        "\n",
        "    # Append normalized image and mask chunks to the respective lists\n",
        "    normalized_images.extend(normalized_image_chunks)\n",
        "    normalized_masks.extend(normalized_mask_chunks)\n",
        "\n",
        "# Convert the image and mask lists to numpy arrays\n",
        "normalized_images = np.array(normalized_images, dtype=object)\n",
        "normalized_masks = np.array(normalized_masks, dtype=object)\n",
        "\n",
        "# Reshape and resize the normalized images and masks\n",
        "reshaped_images = np.array([cv2.resize(image, (384, 96)) for image in normalized_images])\n",
        "reshaped_masks = np.array([cv2.resize(mask, (384, 96)) for mask in normalized_masks])\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "split = int(0.8 * len(reshaped_images))\n",
        "train_images = reshaped_images[:split]\n",
        "train_masks = reshaped_masks[:split]\n",
        "\n",
        "val_images = reshaped_images[split:]\n",
        "val_masks = reshaped_masks[split:]\n",
        "\n",
        "# U-Net model for binarization\n",
        "def unet():\n",
        "    # ... (same as before) ...\n",
        "    inputs = keras.layers.Input(shape=(96, 384, 3))\n",
        "\n",
        "    # Encoder\n",
        "    conv1 = keras.layers.Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
        "    conv1 = keras.layers.Conv2D(64, 3, activation='relu', padding='same')(conv1)\n",
        "    pool1 = keras.layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "    conv2 = keras.layers.Conv2D(128, 3, activation='relu', padding='same')(pool1)\n",
        "    conv2 = keras.layers.Conv2D(128, 3, activation='relu', padding='same')(conv2)\n",
        "    pool2 = keras.layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "    conv3 = keras.layers.Conv2D(256, 3, activation='relu', padding='same')(pool2)\n",
        "    conv3 = keras.layers.Conv2D(256, 3, activation='relu', padding='same')(conv3)\n",
        "    pool3 = keras.layers.MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "    conv4 = keras.layers.Conv2D(512, 3, activation='relu', padding='same')(pool3)\n",
        "    conv4 = keras.layers.Conv2D(512, 3, activation='relu', padding='same')(conv4)\n",
        "    pool4 = keras.layers.MaxPooling2D(pool_size=(2, 2))(conv4)\n",
        "\n",
        "    conv5 = keras.layers.Conv2D(1024, 3, activation='relu', padding='same')(pool4)\n",
        "    conv5 = keras.layers.Conv2D(1024, 3, activation='relu', padding='same')(conv5)\n",
        "\n",
        "    # Decoder\n",
        "    up6 = keras.layers.Conv2DTranspose(512, 2, strides=(2, 2), padding='same')(conv5)\n",
        "    concat6 = keras.layers.concatenate([up6, conv4], axis=3)\n",
        "    conv6 = keras.layers.Conv2D(512, 3, activation='relu', padding='same')(concat6)\n",
        "    conv6 = keras.layers.Conv2D(512, 3, activation='relu', padding='same')(conv6)\n",
        "\n",
        "    up7 = keras.layers.Conv2DTranspose(256, 2, strides=(2, 2), padding='same')(conv6)\n",
        "    concat7 = keras.layers.concatenate([up7, conv3], axis=3)\n",
        "    conv7 = keras.layers.Conv2D(256, 3, activation='relu', padding='same')(concat7)\n",
        "    conv7 = keras.layers.Conv2D(256, 3, activation='relu', padding='same')(conv7)\n",
        "\n",
        "    up8 = keras.layers.Conv2DTranspose(128, 2, strides=(2, 2), padding='same')(conv7)\n",
        "    concat8 = keras.layers.concatenate([up8, conv2], axis=3)\n",
        "    conv8 = keras.layers.Conv2D(128, 3, activation='relu', padding='same')(concat8)\n",
        "    conv8 = keras.layers.Conv2D(128, 3, activation='relu', padding='same')(conv8)\n",
        "\n",
        "    up9 = keras.layers.Conv2DTranspose(64, 2, strides=(2, 2), padding='same')(conv8)\n",
        "    concat9 = keras.layers.concatenate([up9, conv1], axis=3)\n",
        "    conv9 = keras.layers.Conv2D(64, 3, activation='relu', padding='same')(concat9)\n",
        "    conv9 = keras.layers.Conv2D(64, 3, activation='relu', padding='same')(conv9)\n",
        "\n",
        "    output = keras.layers.Conv2D(1, 1, activation='sigmoid')(conv9)\n",
        "\n",
        "    model = keras.models.Model(inputs=inputs, outputs=output)\n",
        "    return model\n",
        "\n",
        "\n",
        "# Create the U-Net model\n",
        "model = unet()\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Reduce batch size for training\n",
        "batch_size = 4\n",
        "\n",
        "# Train the model with reduced batch size\n",
        "model.fit(train_images, train_masks, epochs=20, batch_size=batch_size)\n",
        "\n",
        "# Evaluate the model\n",
        "val_loss, val_acc = model.evaluate(val_images, val_masks)\n",
        "print(\"Validation Loss:\", val_loss)\n",
        "print(\"Validation Accuracy:\", val_acc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5d6oFM00GBK7"
      },
      "outputs": [],
      "source": [
        "model.save(\"U-NET_-cnn-patch_image_new.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e59P_7a0sqkI"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "model = keras.models.load_model(\"/content/gdrive/MyDrive/U-NET_PATCH_IMPLEMENTATION.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k7mjaHs9GHph"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import precision_recall_curve, average_precision_score, roc_curve, auc\n",
        "from skimage.metrics import structural_similarity\n",
        "\n",
        "# Path to the folders containing images and masks\n",
        "image_folder = \"/content/gdrive/MyDrive/ORGINAL_img\"\n",
        "mask_folder = \"/content/gdrive/MyDrive/ORIGINAL_mask\"\n",
        "\n",
        "# Get the list of image and mask filenames\n",
        "image_filenames = sorted(os.listdir(image_folder))\n",
        "mask_filenames = sorted(os.listdir(mask_folder))\n",
        "\n",
        "# Data normalization function\n",
        "def normalize_data(data):\n",
        "    return data / 255.0\n",
        "\n",
        "# Initialize empty lists to store normalized images and masks\n",
        "normalized_images = []\n",
        "normalized_masks = []\n",
        "\n",
        "# Iterate over the image and mask filenames\n",
        "for i in range(len(image_filenames)):\n",
        "    # Load image and mask\n",
        "    image_filename = os.path.join(image_folder, image_filenames[i])\n",
        "    mask_filename = os.path.join(mask_folder, mask_filenames[i])\n",
        "    image = cv2.imread(image_filename)\n",
        "    mask = cv2.imread(mask_filename, cv2.IMREAD_GRAYSCALE)\n",
        "    new_size = (384, 96)\n",
        "    image_resized = cv2.resize(image, new_size)\n",
        "    mask_resized = cv2.resize(mask, new_size)\n",
        "    # Normalize image and mask\n",
        "    normalized_image = normalize_data(image_resized)\n",
        "    normalized_mask = normalize_data(mask_resized)\n",
        "    # Binarize the mask (optional)\n",
        "    normalized_mask = np.where(normalized_mask > 0.5, 1, 0)\n",
        "\n",
        "    # Append normalized images and masks to the respective lists\n",
        "    normalized_images.append(normalized_image)\n",
        "    normalized_masks.append(normalized_mask)\n",
        "\n",
        "# Convert the image and mask lists to numpy arrays\n",
        "normalized_images = np.array(normalized_images)\n",
        "normalized_masks = np.array(normalized_masks)\n",
        "\n",
        "# Load the trained model\n",
        "#model = keras.models.load_model('/content/gdrive/MyDrive/thresholded encoded.h5')\n",
        "\n",
        "# Choose the index of the image you want to test\n",
        "image_index = 10\n",
        "\n",
        "# Get the corresponding test image and mask\n",
        "test_image = normalized_images[image_index]\n",
        "test_mask = normalized_masks[image_index]\n",
        "\n",
        "# Convert the test image and mask to numpy arrays\n",
        "test_images = np.expand_dims(test_image, axis=0)\n",
        "test_masks = np.expand_dims(test_mask, axis=0)\n",
        "\n",
        "# Make predictions on the test image\n",
        "predictions = model.predict(test_images)\n",
        "\n",
        "# Apply threshold to the predicted mask\n",
        "threshold = 0.6\n",
        "predicted_mask = np.where(predictions > threshold, 1, 0)\n",
        "\n",
        "# Display the test image, ground truth mask, and predicted mask\n",
        "fig = plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.imshow(test_image)\n",
        "plt.title(\"Test Image\", fontsize=14)\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.imshow(test_mask, cmap='gray')\n",
        "plt.title(\"Ground Truth Mask\", fontsize=14)\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.imshow(predicted_mask.squeeze(), cmap='gray')\n",
        "plt.title(\"Predicted Mask (Thresholded)\", fontsize=14)\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Save the ground truth mask\n",
        "plt.imsave(\"ground_truth_mask.png\", test_mask, cmap='gray')\n",
        "\n",
        "# Save the predicted mask\n",
        "plt.imsave(\"predicted_mask.png\", predicted_mask.squeeze(), cmap='gray')\n",
        "\n",
        "# Flatten the ground truth mask and predicted mask\n",
        "ground_truth_mask_flat = test_mask.flatten()\n",
        "predicted_mask_flat = predicted_mask.squeeze().flatten()\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision, recall, _ = precision_recall_curve(ground_truth_mask_flat, predicted_mask_flat)\n",
        "f1 = 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "# Calculate ROC curve and AUC\n",
        "fpr, tpr, _ = roc_curve(ground_truth_mask_flat, predicted_mask_flat)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# Calculate mAP\n",
        "ap = average_precision_score(ground_truth_mask_flat, predicted_mask_flat)\n",
        "\n",
        "# Calculate PSNR\n",
        "def calculate_psnr(y_true, y_pred):\n",
        "    mse = np.mean((y_true - y_pred) ** 2)\n",
        "    max_pixel = 1.0  # Assuming pixel values are in the range [0, 1]\n",
        "    psnr = 20 * np.log10(max_pixel / np.sqrt(mse))\n",
        "    return psnr\n",
        "\n",
        "# Calculate DRD\n",
        "def calculate_drd(y_true, y_pred):\n",
        "    drd = np.mean(np.abs(y_true - y_pred))\n",
        "    return drd\n",
        "\n",
        "# Calculate IoU\n",
        "def calculate_iou(y_true, y_pred):\n",
        "    intersection = np.logical_and(y_true, y_pred)\n",
        "    union = np.logical_or(y_true, y_pred)\n",
        "    iou = np.sum(intersection) / np.sum(union)\n",
        "    return iou\n",
        "\n",
        "# Calculate SSIM\n",
        "def calculate_ssim(y_true, y_pred):\n",
        "    ssim = structural_similarity(y_true, y_pred)\n",
        "    return ssim\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "psnr = calculate_psnr(test_mask, predicted_mask.squeeze())\n",
        "drd = calculate_drd(test_mask, predicted_mask.squeeze())\n",
        "iou = calculate_iou(test_mask, predicted_mask.squeeze())\n",
        "ssim = calculate_ssim(test_mask, predicted_mask.squeeze())\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n",
        "print(\"AUC:\", roc_auc)\n",
        "print(\"Mean Average Precision (mAP):\", ap)\n",
        "print(\"Peak Signal-to-Noise Ratio (PSNR):\", psnr)\n",
        "print(\"Dynamic Range Difference (DRD):\", drd)\n",
        "print(\"Intersection-over-Union (IoU):\", iou)\n",
        "print(\"Structural Similarity (SSIM):\", ssim)\n",
        "\n",
        "# Plot ROC curve\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, label='ROC curve (AUC = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}